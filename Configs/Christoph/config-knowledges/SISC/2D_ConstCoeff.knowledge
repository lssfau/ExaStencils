///////////////////////////
// General configuration //
///////////////////////////
useDblPrecision = false

///////////////////////
/// Domain Settings ///
///////////////////////
dimensionality				= 2

minLevel					= 0
maxLevel					= 10
comm_strategyFragment		= 6

domain_onlyRectangular		= true
domain_numBlocks			= 1
domain_numFragmentsPerBlock	= 1
domain_fragmentLength_x		= 1
domain_fragmentLength_y		= 1
domain_fragmentLength_z		= 1

domain_rect_generate		= true
domain_rect_numBlocks_x		= 1
domain_rect_numBlocks_y		= 1
domain_rect_numBlocks_z		= 1
domain_rect_numFragsPerBlock_x	= 1
domain_rect_numFragsPerBlock_y	= 1
domain_rect_numFragsPerBlock_z	= 1

///////////////////
/// L3 Settings ///
///////////////////
l3tmp_generateL4			= true
l3tmp_genForAutoTests		= false

l3tmp_sisc					= true
l3tmp_genStencilFields		= false
l3tmp_genHDepStencils		= true
l3tmp_genNonZeroRhs			= true

l3tmp_exactSolution			= "Kappa"

l3tmp_smoother				= "Jac"
l3tmp_numPre				= 3
l3tmp_numPost				= 3
l3tmp_useSlotsForJac		= true
l3tmp_useSlotVariables		= true
l3tmp_useMaxNormForError	= true

l3tmp_genTimersPerFunction  = true
l3tmp_genTimersPerLevel     = true
l3tmp_printAllTimers        = true
l3tmp_printError            = true

l3tmp_targetResReduction    = 0.01
l3tmp_initSolWithRand       = false
l3tmp_omega                 = 0.79
l3tmp_maxNumCGSSteps        = 1024

l3tmp_genTemporalBlocking   = false

///////////////////
// Optimizations //
///////////////////
// Polyhedron optimizations
// Polyhedron optimizations
poly_optLevel_fine          = 3
poly_optLevel_coarse        = 1
poly_numFinestLevels        = 1
poly_performDCE             = false // this is not working with CUDA
poly_tileSize_x             = 0
poly_tileSize_y             = 0
poly_tileSize_z             = 0
poly_tileOuterLoop          = false
poly_filterDeps             = true

// other optimizations
opt_useAddressPrecalc           = false
opt_vectorize                   = false
opt_unroll                      = 2
opt_unroll_interleave           = true
opt_conventionalCSE             = false // works only with useDblPrecision = true
opt_loopCarriedCSE              = false // this is not working with CUDA

///////////////////
/// Parallelism ///
///////////////////
// OpenMP
omp_enabled					= false
omp_numThreads				= 1

// MPI
mpi_enabled					= false
mpi_numThreads				= 1

////////////
/// Cuda ///
////////////
cuda_enabled                       = true
//cuda_deviceId                      = 0
cuda_preferredExecution            = "Device"
cuda_syncDeviceAfterKernelCalls    = true
cuda_syncHostForWrites             = false
cuda_syncDeviceForWrites           = true
cuda_blockSize_x                   = 16
cuda_blockSize_y                   = 16
cuda_blockSize_z                   = 1
// default (1D) block size for default reduction kernels
cuda_reductionBlockSize            = 1024

// my new experimental cuda properties
cuda_useSharedMemory               = true
cuda_linearizeSharedMemoryAccess   = false
cuda_favorL1CacheOverSharedMemory  = false
cuda_spatialBlockingWithSmem       = true
cuda_spatialBlockingWithROC        = false
